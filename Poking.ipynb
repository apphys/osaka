{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import copy\n",
    "from pdb import set_trace\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "from dataloaders import init_dataloaders\n",
    "\n",
    "from MAML.model import ModelConvSynbols, ModelConvOmniglot, ModelConvMiniImagenet, ModelMLPSinusoid\n",
    "from MAML.metalearners import ModelAgnosticMetaLearning, ModularMAML, ProtoMAML\n",
    "from MAML.utils import ToTensor1D, set_seed, is_connected\n",
    "\n",
    "from Utils.bgd_lib.bgd_optimizer import create_BGD_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from omniglot.npy.\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "from collections import namedtuple\n",
    "import main\n",
    "\n",
    "# Meta dataloaders\n",
    "MetaDLs = namedtuple('MetaDLs', 'train val cl')\n",
    "\n",
    "args = SimpleNamespace(\n",
    "    dataset='omniglot',\n",
    "    folder='Data',\n",
    "    num_shots=5, # default=5\n",
    "    num_ways=5,  # default=5\n",
    "    num_shots_test=15, # default=15\n",
    "    batch_size=25,     # default=25\n",
    "    # CL args group\n",
    "    prob_statio=0.98,  # default=0.98\n",
    "    task_sequence=None, # default=None\n",
    "    n_steps_per_task=1, # default=1\n",
    "    use_different_nways=False, # default=False\n",
    ")\n",
    "args.device = torch.device('cuda')\n",
    "\n",
    "meta_dls = MetaDLs(*init_dataloaders(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing models...\n"
     ]
    }
   ],
   "source": [
    "print('Initializing models...')\n",
    "wandb = None\n",
    "args.meta_lr = 0.001\n",
    "    \n",
    "def init_models():\n",
    "    model = ModelConvOmniglot(args.num_ways, hidden_size=64, deeper=0)\n",
    "    loss_function = F.cross_entropy\n",
    "\n",
    "    meta_optimizer = torch.optim.Adam(model.parameters(), lr=args.meta_lr)\n",
    "    meta_optimizer_cl = meta_optimizer\n",
    "\n",
    "    metalearner = ModelAgnosticMetaLearning(\n",
    "        model, meta_optimizer, loss_function, args=SimpleNamespace(\n",
    "            device=args.device,\n",
    "            num_ways=args.num_ways,\n",
    "            # Size of the fast adaptation step, ie. learning rate in the gradient descent update.\n",
    "            step_size = 0.1, \n",
    "            is_classification_task = True,\n",
    "             # 'Use the first order approximation, do not use higher-order derivatives during meta-optimization.\n",
    "            first_order = 0,\n",
    "            # for MRCL, freeze all conv layers at cl time\n",
    "            freeze_visual_features = 0,\n",
    "             # number of inner updates\n",
    "            num_steps = 1,  # aka num_adaptation_steps\n",
    "            # Whether or not to learn the (inner loop) step-size. \n",
    "            learn_step_size = False,\n",
    "            # power for update modulation\n",
    "            um_power = 0,\n",
    "            # Whether ot not to learn param specific step-size\n",
    "            per_param_step_size = False,\n",
    "        ))\n",
    "    return metalearner, meta_optimizer, meta_optimizer_cl\n",
    "\n",
    "metalearner, meta_optimizer, meta_optimizer_cl = init_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pretraining for 2 epochs...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 100/100 [00:05<00:00, 18.61it/s, accuracy=0.8661, inner_loss=1.7562, loss=0.4014]       \n",
      "Training:   1%|          | 1/100 [00:00<00:12,  7.90it/s, accuracy=0.9552, inner_loss=1.7310, outer_loss=0.1694]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] results: {'mean_outer_loss': 0.4014275380969048, 'accuracies_after': 0.866093360185623, 'mean_inner_loss': 1.7562124276161193}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 100/100 [00:05<00:00, 18.69it/s, accuracy=0.8980, inner_loss=1.7297, loss=0.2999]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] results: {'mean_outer_loss': 0.29987873092293743, 'accuracies_after': 0.8980400258302692, 'mean_inner_loss': 1.72973963022232}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "num_batches = 100 # Number of batch of tasks per epoch (default: 100)\n",
    "verbose = True\n",
    "patience = 5\n",
    "\n",
    "best_val = 0.\n",
    "epochs_overfitting = 0\n",
    "epoch_desc = 'Epoch {{0: <{0}d}}'.format(1 + int(math.log10(num_epochs)))\n",
    "print(f'\\npretraining for {num_epochs} epochs...\\n')\n",
    "for epoch in range(num_epochs):\n",
    "    metalearner.train(\n",
    "        meta_dls.train,\n",
    "        max_batches=num_batches,\n",
    "        verbose=verbose,\n",
    "        desc='Training',\n",
    "        leave=False)\n",
    "    results = metalearner.evaluate(\n",
    "        meta_dls.val,\n",
    "        max_batches=num_batches,\n",
    "        verbose=verbose,\n",
    "        epoch=epoch,\n",
    "        desc=epoch_desc.format(epoch + 1))\n",
    "    \n",
    "    print(f'[{epoch}] results: {results}')\n",
    "    result_val = results['accuracies_after']\n",
    "    # early stopping:\n",
    "    if best_val < result_val:\n",
    "        epochs_overfitting = 0\n",
    "        best_val = result_val\n",
    "        best_metalearner = copy.deepcopy(metalearner)\n",
    "    else:\n",
    "        epochs_overfitting += 1\n",
    "        if epochs_overfitting > patience:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continual Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_model_init = copy.deepcopy(metalearner)\n",
    "del metalearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Single run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 100 # number of timesteps for the CL exp\n",
    "algo3 = False\n",
    "\n",
    "# TODO: why aren't most of these set within cl_model.__init__?\n",
    "cl_model_init.optimizer_cl = meta_optimizer_cl\n",
    "cl_model_init.cl_strategy = 'loss'\n",
    " # threshold for training on incoming data or not\n",
    "cl_model_init.cl_strategy_thres = 4.0\n",
    "# threshold for task boundary detection (-1 to turn off)\n",
    "cl_model_init.cl_tbd_thres = -1 \n",
    "if 0: # turn off meta-learning at CL time (TODO: wat)\n",
    "    cl_model_init.no_meta_learning = True\n",
    "\n",
    "cl_model = copy.deepcopy(cl_model_init)\n",
    "_, _, meta_optimizer_cl = init_models()\n",
    "cl_model.optimizer_cl = meta_optimizer_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = ['train', 'test', 'ood']\n",
    "accuracies = np.zeros([n_runs, timesteps])\n",
    "tbds = np.zeros([n_runs, timesteps])\n",
    "avg_accuracies_mode = dict(zip(modes, [[], [], []]))\n",
    "accuracies_mode = dict(zip(modes, [[], [], []]))\n",
    "\n",
    "for i, batch in enumerate(meta_dls.cl):\n",
    "    data, labels, task_switch, mode, _, _ = batch\n",
    "    if algo3:\n",
    "        results = cl_model.observe2(batch)\n",
    "    else:\n",
    "        results = cl_model.observe(batch)\n",
    "\n",
    "    # Reporting:\n",
    "    accuracy_after = results[\"accuracy_after\"]\n",
    "    accuracies[run, i] = accuracy_after\n",
    "    accuracies_mode[mode[0]].append(accuracy_after)\n",
    "    tbds[run, i] = float(results['tbd'])\n",
    "\n",
    "    if (verbose and i % 100 == 0) or i == timesteps - 1:\n",
    "        acc = np.mean(accuracies[run, :i])\n",
    "        acc_mode = []\n",
    "        for mode in modes:\n",
    "            acc_mode.append(np.mean(accuracies_mode[mode]))\n",
    "        acc_mode_str = [f'{m}_acc={a:.2f}' for m, a in zip(modes, acc_mode)]\n",
    "        print(f'total Acc: {acc:.2f},', f'mode accs: {acc_mode_str}', end='\\t')\n",
    "        # Note: tbd==task boundary detection\n",
    "        tbd = np.mean(tbds[run, :i])\n",
    "        print(f'Total tbd: {tbd:.2f}', f'it: {i}', sep='\\t')\n",
    "\n",
    "    if i == timesteps - 1:\n",
    "        for mode in modes:\n",
    "            avg_accuracies_mode[mode].append(np.mean(accuracies_mode[mode]))\n",
    "        if run == 0 and is_classification_task:\n",
    "            if acc < 1. / float(args.num_ways) + 0.2:\n",
    "                print({'fail': 1})\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(meta_dls.cl):\n",
    "    data, labels, task_switch, mode, ways, shots = batch\n",
    "    if algo3:\n",
    "        results = cl_model.observe2(batch)\n",
    "    else:\n",
    "        results = cl_model.observe(batch)\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
       "         4]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 25, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    args, wandb = boilerplate(args)\n",
    "\n",
    "    print('Initializing dataloaders...')\n",
    "    # Notes:\n",
    "    # - the train/val meta dls yield batches of {'train', 'test', 'ways', 'shots_tr', 'shots_te'}\n",
    "    # - the cl meta dl yields list of 6 tensors (TODO?)\n",
    "    meta_train_dataloader, meta_val_dataloader, cl_dataloader = init_dataloaders(args)\n",
    "\n",
    "\n",
    "\n",
    "    print('Executing pretraining...')\n",
    "    cl_model_init = pretraining(\n",
    "        args,\n",
    "        wandb,\n",
    "        metalearner,\n",
    "        meta_train_dataloader,\n",
    "        meta_val_dataloader)\n",
    "\n",
    "    print('Executing continual learning...')\n",
    "    continual_learning(\n",
    "        args,\n",
    "        wandb,\n",
    "        cl_model_init,\n",
    "        meta_optimizer_cl,\n",
    "        cl_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
